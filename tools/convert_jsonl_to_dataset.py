#!/usr/bin/env python3
"""
Convert JSONL format to Higgs Audio training dataset
Fixed version with correct paths and metadata generation
"""

import json
import os
import shutil
import torchaudio
from pathlib import Path
from typing import List, Dict
import argparse
from tqdm import tqdm

def load_jsonl(file_path: str) -> List[Dict]:
    """Load JSONL file"""
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                data.append(json.loads(line))
    return data

def get_audio_duration(audio_path: str) -> float:
    """Get audio duration in seconds"""
    try:
        waveform, sample_rate = torchaudio.load(audio_path)
        duration = waveform.shape[1] / sample_rate
        return round(duration, 2)
    except Exception as e:
        print(f"Error loading audio {audio_path}: {e}")
        return 0.0

def extract_speaker_info(jsonl_path: str) -> Dict[str, str]:
    """Extract speaker information from file path"""
    file_name = Path(jsonl_path).stem
    
    # æ ¹æ®æ–‡ä»¶åæ¨æ–­è¯´è¯äººä¿¡æ¯
    if "tun" in file_name.lower():
        return {
            "speaker_id": "tun_speaker",
            "speaker_name": "Tun",
            "language": "zh",
            "gender": "unknown"
        }
    elif "huo" in file_name.lower():
        return {
            "speaker_id": "huo_speaker", 
            "speaker_name": "Huo",
            "language": "zh",
            "gender": "unknown"
        }
    else:
        return {
            "speaker_id": "unknown_speaker",
            "speaker_name": "Unknown",
            "language": "zh",
            "gender": "unknown"
        }

def analyze_emotion_from_text(text: str) -> str:
    """Simple emotion analysis based on text content"""
    text = text.lower()
    
    if any(word in text for word in ["ï¼Ÿ", "?", "ä»€ä¹ˆ", "å“ª", "æ€ä¹ˆ"]):
        return "questioning"
    elif any(word in text for word in ["ï¼", "!", "å¥½çš„", "æ˜¯çš„", "å¯¹"]):
        return "affirming"
    elif any(word in text for word in ["è¶…æ—¶", "é”™è¯¯", "å¤±è´¥"]):
        return "alerting"
    else:
        return "neutral"

def determine_scene(audio_path: str, text: str) -> str:
    """Determine scene based on audio path and text content"""
    if "phone" in audio_path.lower() or "ç”µè¯" in text:
        return "phone_call"
    elif "meeting" in audio_path.lower() or "ä¼šè®®" in text:
        return "meeting_room"
    elif "å½•éŸ³" in text or "æŒ‰é”®" in text:
        return "recording_system"
    else:
        return "quiet_room"

def convert_jsonl_to_dataset(
    jsonl_files: List[str],
    output_dir: str,
    copy_audio: bool = True,
    max_samples_per_speaker: int = None
):
    """Convert JSONL files to Higgs Audio dataset format"""
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print(f"Creating dataset in: {output_path}")
    
    all_samples = []
    sample_counter = 0
    
    for jsonl_file in jsonl_files:
        print(f"\nProcessing {jsonl_file}...")
        
        if not os.path.exists(jsonl_file):
            print(f"Error: JSONL file not found: {jsonl_file}")
            continue
        
        # åŠ è½½JSONLæ•°æ®
        try:
            data = load_jsonl(jsonl_file)
        except Exception as e:
            print(f"Error loading JSONL file {jsonl_file}: {e}")
            continue
        
        # è·å–è¯´è¯äººä¿¡æ¯
        speaker_info = extract_speaker_info(jsonl_file)
        speaker_id = speaker_info["speaker_id"]
        
        print(f"Found {len(data)} samples for speaker {speaker_id}")
        
        # é™åˆ¶æ¯ä¸ªè¯´è¯äººçš„æ ·æœ¬æ•°é‡
        if max_samples_per_speaker and len(data) > max_samples_per_speaker:
            data = data[:max_samples_per_speaker]
            print(f"Limited to {len(data)} samples for speaker {speaker_id}")
        
        processed_count = 0
        
        for idx, item in enumerate(tqdm(data, desc=f"Processing {speaker_id}")):
            try:
                # è§£ææ¶ˆæ¯
                messages = item.get("messages", [])
                audios = item.get("audios", [])
                
                if not messages or not audios:
                    continue
                
                # æ‰¾åˆ°ç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹å›å¤
                user_content = None
                assistant_content = None
                
                for msg in messages:
                    if msg["role"] == "user":
                        user_content = msg["content"]
                    elif msg["role"] == "assistant":
                        assistant_content = msg["content"]
                
                if not assistant_content or not audios:
                    continue
                
                # è·å–éŸ³é¢‘æ–‡ä»¶è·¯å¾„
                original_audio_path = audios[0]
                if not os.path.exists(original_audio_path):
                    print(f"Audio file not found: {original_audio_path}")
                    continue
                
                # ç”Ÿæˆæ–°çš„æ–‡ä»¶å - ç›´æ¥æ”¾åœ¨è¾“å‡ºç›®å½•æ ¹ç›®å½•
                sample_id = f"{speaker_id}_{sample_counter:06d}"
                audio_filename = f"{sample_id}.wav"
                transcript_filename = f"{sample_id}.txt"
                
                # éŸ³é¢‘æ–‡ä»¶è·¯å¾„ - ç›´æ¥åœ¨è¾“å‡ºç›®å½•æ ¹ç›®å½•
                new_audio_path = output_path / audio_filename
                transcript_path = output_path / transcript_filename
                
                # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶
                try:
                    if copy_audio:
                        shutil.copy2(original_audio_path, new_audio_path)
                    else:
                        # åˆ›å»ºç¬¦å·é“¾æ¥
                        if new_audio_path.exists():
                            new_audio_path.unlink()
                        new_audio_path.symlink_to(os.path.abspath(original_audio_path))
                except Exception as e:
                    print(f"Error copying audio file {original_audio_path}: {e}")
                    continue
                
                # åˆ›å»ºè½¬å½•æ–‡ä»¶
                try:
                    with open(transcript_path, 'w', encoding='utf-8') as f:
                        f.write(assistant_content.strip())
                except Exception as e:
                    print(f"Error writing transcript file {transcript_path}: {e}")
                    continue
                
                # è·å–éŸ³é¢‘æ—¶é•¿
                duration = get_audio_duration(str(new_audio_path))
                
                if duration == 0:
                    print(f"Skipping sample with invalid audio: {new_audio_path}")
                    # æ¸…ç†å·²åˆ›å»ºçš„æ–‡ä»¶
                    if new_audio_path.exists():
                        new_audio_path.unlink()
                    if transcript_path.exists():
                        transcript_path.unlink()
                    continue
                
                # åˆ†ææƒ…æ„Ÿå’Œåœºæ™¯
                emotion = analyze_emotion_from_text(assistant_content)
                scene = determine_scene(original_audio_path, assistant_content)
                
                # åˆ›å»ºæ ·æœ¬å…ƒæ•°æ® - ä½¿ç”¨æ–‡ä»¶åè€Œä¸æ˜¯ç›¸å¯¹è·¯å¾„
                sample_meta = {
                    "id": sample_id,
                    "audio_file": audio_filename,  # ç›´æ¥ä½¿ç”¨æ–‡ä»¶å
                    "transcript_file": transcript_filename,  # ç›´æ¥ä½¿ç”¨æ–‡ä»¶å
                    "duration": duration,
                    "speaker_id": speaker_id,
                    "speaker_name": speaker_info["speaker_name"],
                    "scene": scene,
                    "emotion": emotion,
                    "language": speaker_info["language"],
                    "gender": speaker_info["gender"],
                    "quality_score": 1.0,
                    "original_audio_path": original_audio_path,
                    "user_instruction": user_content,
                    "task_type": "audio_generation"
                }
                
                all_samples.append(sample_meta)
                sample_counter += 1
                processed_count += 1
                
            except Exception as e:
                print(f"Error processing sample {idx} from {jsonl_file}: {e}")
                continue
        
        print(f"Successfully processed {processed_count} samples for {speaker_id}")
    
    if not all_samples:
        print("Error: No valid samples were processed!")
        return False
    
    # åˆ›å»ºmetadata.json
    total_duration = sum(s["duration"] for s in all_samples)
    avg_duration = total_duration / len(all_samples)
    
    metadata = {
        "dataset_info": {
            "total_samples": len(all_samples),
            "speakers": list(set(s["speaker_id"] for s in all_samples)),
            "languages": list(set(s["language"] for s in all_samples)),
            "total_duration": round(total_duration, 2),
            "avg_duration": round(avg_duration, 2),
            "created_from": jsonl_files
        },
        "samples": all_samples
    }
    
    metadata_path = output_path / "metadata.json"
    try:
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        print(f"\nSuccessfully created metadata.json at: {metadata_path}")
    except Exception as e:
        print(f"Error creating metadata.json: {e}")
        return False
    
    print(f"\nâœ… Dataset conversion completed!")
    print(f"ğŸ“ Output directory: {output_dir}")
    print(f"ğŸ“Š Total samples: {len(all_samples)}")
    print(f"ğŸµ Total duration: {total_duration/3600:.2f} hours")
    print(f"â±ï¸  Average duration: {avg_duration:.2f} seconds")
    print(f"ğŸ¤ Speakers: {', '.join(metadata['dataset_info']['speakers'])}")
    
    # ç»Ÿè®¡å„è¯´è¯äººæ ·æœ¬æ•°
    speaker_counts = {}
    for sample in all_samples:
        speaker_id = sample["speaker_id"] 
        speaker_counts[speaker_id] = speaker_counts.get(speaker_id, 0) + 1
    
    print(f"\nğŸ“ˆ Samples per speaker:")
    for speaker, count in speaker_counts.items():
        print(f"   - {speaker}: {count} samples")
    
    # éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
    print(f"\nğŸ” Verification:")
    audio_count = len(list(output_path.glob("*.wav")))
    txt_count = len(list(output_path.glob("*.txt")))
    print(f"   - Audio files: {audio_count}")
    print(f"   - Text files: {txt_count}")
    print(f"   - Metadata file: {'âœ…' if metadata_path.exists() else 'âŒ'}")
    
    return True

def main():
    parser = argparse.ArgumentParser(description="Convert JSONL to Higgs Audio dataset")
    
    parser.add_argument(
        "--jsonl_files", 
        nargs="+",
        default=[
            # "/root/code/new_work_code/HI-TransPA/swfit_workdir/fresh-little-lemon-workspace/data/swift_format/tun_audio.jsonl",
            "/root/code/new_work_code/HI-TransPA/swfit_workdir/fresh-little-lemon-workspace/data/swift_format/huo_audio.jsonl"
        ],
        help="Path to JSONL files"
    )
    
    parser.add_argument(
        "--output_dir",
        default="/root/code/higgs-audio-main/higgs_training_data_huo",
        help="Output directory for the dataset"
    )
    
    parser.add_argument(
        "--copy_audio",
        action="store_true",
        default=True,
        help="Copy audio files instead of creating symlinks"
    )
    
    parser.add_argument(
        "--max_samples_per_speaker",
        type=int,
        default=None,
        help="Maximum number of samples per speaker (None for no limit)"
    )
    
    parser.add_argument(
        "--clean_output_dir",
        action="store_true",
        help="Clean output directory before conversion"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    for jsonl_file in args.jsonl_files:
        if not os.path.exists(jsonl_file):
            print(f"âŒ Error: JSONL file not found: {jsonl_file}")
            return
    
    # æ¸…ç†è¾“å‡ºç›®å½•ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if args.clean_output_dir and os.path.exists(args.output_dir):
        print(f"ğŸ§¹ Cleaning output directory: {args.output_dir}")
        shutil.rmtree(args.output_dir)
    
    # è½¬æ¢æ•°æ®é›†
    success = convert_jsonl_to_dataset(
        jsonl_files=args.jsonl_files,
        output_dir=args.output_dir,
        copy_audio=args.copy_audio,
        max_samples_per_speaker=args.max_samples_per_speaker
    )
    
    if success:
        print(f"\nğŸ‰ Conversion completed successfully!")
        print(f"You can now run training with:")
        print(f"python train_higgs_audio.py --train_data_dir {args.output_dir}")
    else:
        print(f"\nâŒ Conversion failed!")

if __name__ == "__main__":
    main()